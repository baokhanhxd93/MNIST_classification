{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fe73df",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855b045",
   "metadata": {},
   "source": [
    "This project use MNIST (\"Modified National Institute of Standards and Technology\") data set to build a model handwritten images classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f325aba",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822ff083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the nessesery libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd363fb",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7e1c7",
   "metadata": {},
   "source": [
    "## 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abea4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data are ready!!\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "print(\"Data are ready!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded9b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size is (42000, 785)\n",
      "Testing data size is (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size is {train.shape}\\nTesting data size is {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f91f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000,), (42000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"], axis=1)\n",
    "Y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefaa89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load more data sets from mnist of keras\n",
    "(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
    "x_train1.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cbd969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000, 28, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1 = np.concatenate([x_train1, x_test1], axis=0)\n",
    "y_train1 = np.concatenate([y_train1, y_test1], axis=0)\n",
    "\n",
    "Y_train1 = y_train1\n",
    "X_train1 = x_train1.reshape(-1, 28*28)\n",
    "X_train1.shape, x_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480aa635",
   "metadata": {},
   "source": [
    "### Is the taget label balanced? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4db0f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print data histogram\n",
    "sns.countplot(x=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17ee9a",
   "metadata": {},
   "source": [
    "## 2.2 Nomarlization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c31dc2",
   "metadata": {},
   "source": [
    "CNN converg faster on [0..1] data than on [0-255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "X_train1 = X_train1 / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459b767",
   "metadata": {},
   "source": [
    "### Merging all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f80d3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112000, 784), (112000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train.values, X_train1))\n",
    "Y_train = np.concatenate((Y_train, Y_train1))\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cc30a",
   "metadata": {},
   "source": [
    "## 2.3 Reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826eca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimention because input of CNN is tensor 4 dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33080376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label to one-hot vector\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29201745",
   "metadata": {},
   "source": [
    "## 2.4 Split training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17e31c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100800, 28, 28, 1), (11200, 28, 28, 1), (100800, 10), (11200, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3548636",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6048aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbaa38f4610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[189][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7e8d1",
   "metadata": {},
   "source": [
    "# 3. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b078a47",
   "metadata": {},
   "source": [
    "## 3.1 Define the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d40df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 10:52:22.382892: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-05 10:52:22.384039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-05 10:52:22.454284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.455050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-04-05 10:52:22.455137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-05 10:52:22.460924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-05 10:52:22.461101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-05 10:52:22.465288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-05 10:52:22.467180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-05 10:52:22.470992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-05 10:52:22.472358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-05 10:52:22.477919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-05 10:52:22.478091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.478582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.478893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-05 10:52:22.479737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 10:52:22.480363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.480737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-04-05 10:52:22.480788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-05 10:52:22.480816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-05 10:52:22.480837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-05 10:52:22.480857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-05 10:52:22.480878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-05 10:52:22.480898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-05 10:52:22.480919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-05 10:52:22.480942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-05 10:52:22.481019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.481348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.481610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-05 10:52:22.481659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-05 10:52:22.846036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-05 10:52:22.846073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-05 10:52:22.846079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-05 10:52:22.846311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.846584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.846810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-05 10:52:22.847008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3199 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-04-05 10:52:22.847212: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Creating CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding=\"Same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"Same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"Same\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88abe813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# print out model look\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e9637c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: './model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/formatters.py:973\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    970\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1022\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m   1021\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[0;32m-> 1022\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m   1024\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: './model.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: './model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1054\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[0;32m-> 1054\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/IPython/core/display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: './model.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('./model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b00544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9acb13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_creossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e933ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust lr\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c56b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2a5ab",
   "metadata": {},
   "source": [
    "## 3.2 Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "755b951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # Set input mean to 0 over the dataset, feature-wise.\n",
    "    samplewise_center=False, # Set each sample mean to 0.\n",
    "    featurewise_std_normalization=False, # Divide inputs by std of the dataset, feature-wise.\n",
    "    samplewise_std_normalization=False, # Divide each input by its std.\n",
    "    zca_whitening=False, # Apply ZCA whitening.\n",
    "    rotation_range=10, # Degree range for random rotations.\n",
    "    zoom_range=0.1, # Range for random zoom.\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False, # randomly flip images\n",
    "    vertical_flip=False # randomly flip images\n",
    ")\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "train_gen = datagen.flow(X_train, Y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0c897",
   "metadata": {},
   "source": [
    "For the data augmentation, i choosed to :\n",
    "\n",
    "Randomly rotate some training images by 10 degrees\n",
    "Randomly Zoom by 10% some training images\n",
    "Randomly shift images horizontally by 10% of the width\n",
    "Randomly shift images vertically by 10% of the height\n",
    "I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n",
    "\n",
    "Once our model is ready, we fit the training dataset ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cccd30",
   "metadata": {},
   "source": [
    "## 3.3 Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea13fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:14:04.069855: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-05 12:14:04.090320: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2799925000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:186 __call__\n        self.build(y_pred)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:139 build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:262 _get_loss_object\n        loss = losses_mod.get(loss)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1899 get\n        return deserialize(identifier)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1854 deserialize\n        return deserialize_keras_object(\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: categorical_creossentropy\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# prediction model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:186 __call__\n        self.build(y_pred)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:139 build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:262 _get_loss_object\n        loss = losses_mod.get(loss)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1899 get\n        return deserialize(identifier)\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1854 deserialize\n        return deserialize_keras_object(\n    /home/baokhanh/anaconda3/envs/MachineLearningPractice/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: categorical_creossentropy\n"
     ]
    }
   ],
   "source": [
    "# prediction model\n",
    "history = model.fit(train_gen,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=2,\n",
    "                    steps_per_epoch=X_train.shape[0]//batch_size,\n",
    "                    callbacks=[learning_rate_reduction],\n",
    "                    validation_steps=X_val.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7b696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
